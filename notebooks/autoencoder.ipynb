{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Candlestick AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_pickle(\"../input/candlestick-eda/data_df.pkl\")\n",
    "print(data_df.shape)\n",
    "data_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    n_filters = 16\n",
    "    input_img = keras.Input(shape=(40, 40, 1))\n",
    "#     encoded_img = keras.Input(shape=(5, 5, 4))\n",
    "    \n",
    "    x = layers.Conv2D(n_filters, (2, 2), activation=None, padding='same')(input_img)\n",
    "    x = layers.Conv2D(n_filters, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = layers.BatchNormalization(trainable = False)(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(n_filters, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.Conv2D(n_filters, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = layers.BatchNormalization(trainable = False)(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(n_filters, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.Conv2D(n_filters, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    x = layers.Conv2D(n_filters, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    x = layers.Conv2D(n_filters, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    x = layers.BatchNormalization(trainable = False)(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(n_filters, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.Conv2D(n_filters, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    x = layers.BatchNormalization(trainable = False)(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.Conv2D(n_filters, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    decoded = layers.Conv2D(1, (2, 2), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    autoencoder = keras.Model(input_img, decoded)\n",
    "    \n",
    "    encoder = keras.Model(input_img, encoded)\n",
    "    \n",
    "    # decoder_layers = autoencoder.layers[-10:]\n",
    "    # decoder = keras.Model(encoded_img, decoder_layers(decoded))\n",
    "    decoder = None\n",
    "    \n",
    "    return encoder, decoder, autoencoder\n",
    "\n",
    "encoder, decoder, autoencoder = define_model()\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_df.sort_values(\"imgID\")[\"imgData\"].apply(lambda x: x.reshape(1,40,40,1))\n",
    "X = np.concatenate(X.values)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1291)\n",
    "\n",
    "encoder, decoder, autoencoder = define_model()\n",
    "adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "autoencoder.compile(optimizer=adam, loss='binary_crossentropy')\n",
    "\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.00001,\n",
    "    patience=15,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    restore_best_weights=True)\n",
    "ckp = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"best_model.ckp\",\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    save_freq='epoch',\n",
    ")\n",
    "\n",
    "autoencoder.fit(X, X, \n",
    "                batch_size=128,\n",
    "                epochs=1500,\n",
    "                verbose=1,\n",
    "                validation_split=0.2,\n",
    "                callbacks=[es, ckp] \n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(autoencoder.history.history[\"loss\"], \".:\")\n",
    "plt.plot(autoencoder.history.history[\"val_loss\"], \".:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = keras.models.load_model('best_model.ckp')\n",
    "reconstucts = autoencoder.predict(X[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    plt.imshow(np.concatenate([X[i],reconstucts[i]],1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.predict(X[:5]).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
