{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import mplfinance as mplf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__version__, pd.__version__, tf.__version__, keras.__version__, sklearn.__version__, mplf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1291"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlc = pd.read_csv(\"../input/candle-stick-patterns/ohlc.csv\", index_col=0, parse_dates=True)\n",
    "print(ohlc.shape)\n",
    "ohlc[:3]\n",
    "\n",
    "data_df = pd.read_pickle(\"../input/candlestick-eda/data_df.pkl\")\n",
    "data_df = data_df.sort_values(\"imgID\").reset_index(drop=True)\n",
    "print(data_df.shape)\n",
    "data_df[:3]\n",
    "\n",
    "Data_Size = data_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.concat([ohlc.reset_index(drop=True)[:Data_Size],data_df],1)\n",
    "print(data_df.shape)\n",
    "data_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBars = 3\n",
    "window_size = 5\n",
    "targetBarPos = 3\n",
    "\n",
    "\n",
    "pct_changes = ((ohlc[\"high\"].shift(-(targetBarPos+NBars)).rolling(window_size, center=True).mean() - ohlc[\"high\"])/ohlc[\"high\"])\n",
    "pct_changes.plot(kind=\"hist\", bins=120)\n",
    "plt.xlim(-0.5,0.5)\n",
    "plt.xscale(\"symlog\")\n",
    "plt.show()\n",
    "\n",
    "# categorize ranges of change\n",
    "qsize = 0.125\n",
    "qs = np.arange(0,1+qsize,qsize)\n",
    "qranges = pd.qcut(pct_changes, q = qs)\n",
    "print(qs)\n",
    "print(qranges.value_counts())\n",
    "\n",
    "# use top ranges as 1 and others as 0\n",
    "data_df[\"h_labels\"] = qranges.cat.codes.values[:Data_Size]\n",
    "data_df[\"ts\"] = qranges.index[:Data_Size]\n",
    "data_df = data_df.set_index(\"ts\")\n",
    "data_df[\"h_labels\"] = data_df[\"h_labels\"].map({\n",
    "    7:1, 6:1, \n",
    "    0:2, 1:2\n",
    "})\n",
    "data_df[\"h_labels\"] = data_df[\"h_labels\"].fillna(0) # should drop -1 first, not handled here\n",
    "\n",
    "dict(\n",
    "    zip(\n",
    "        qranges.cat.categories, \n",
    "        range(len(qranges.cat.categories))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerp X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_df.sort_values(\"imgID\")[\"imgData\"].apply(lambda x: x.reshape(1,40,40,1))\n",
    "X = np.concatenate(X.values)\n",
    "X.shape\n",
    "\n",
    "y = data_df[\"h_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts() # 1: buy, 2: sell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = (y.astype(int).value_counts().max() / y.astype(int).value_counts()).to_dict()\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = TimeSeriesSplit(n_splits=2)\n",
    "for train_idx, test_idx in tss.split(X,y):\n",
    "    break\n",
    "\n",
    "X_tr, X_ts = X[train_idx], X[test_idx]\n",
    "y_tr, y_ts = keras.utils.to_categorical(y[train_idx]), keras.utils.to_categorical(y[test_idx])\n",
    "\n",
    "[x.shape for x in [X_tr, X_ts, y_tr, y_ts]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = keras.models.load_model('../input/candle-stick-autoencoder/best_model.ckp')\n",
    "# model.summary()\n",
    "encoder = keras.models.Sequential(model.layers[:15])\n",
    "encoder.compile(optimizer=\"adam\", loss='binary_crossentropy')\n",
    "\n",
    "for layer in encoder.layers: layer.trainable = False\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    clf = keras.models.Sequential(encoder.layers + \n",
    "                                 [\n",
    "                                     layers.Flatten(),\n",
    "                                     layers.Dense(256, activation=\"relu\", name=\"dense_clf\"),\n",
    "                                     layers.BatchNormalization(trainable=False, name=\"bn1\"),\n",
    "                                     layers.Dropout(0.3, name=\"drop_clf1\"),\n",
    "                                     layers.Dense(128, activation=\"relu\", name=\"dense_clf_1\"),\n",
    "                                     layers.BatchNormalization(trainable=False, name=\"bn2\"),\n",
    "                                     layers.Dropout(0.3, name=\"drop_clf2\"),\n",
    "                                     layers.Dense(64, activation=\"relu\", name=\"dense_clf_2\"),\n",
    "                                     layers.BatchNormalization(trainable=False, name=\"bn3\"),\n",
    "                                     layers.Dropout(0.3, name=\"drop_clf3\"),\n",
    "                                     layers.Dense(12, activation=\"relu\", name=\"dense_clf_3\"),\n",
    "                                     layers.Dense(3, activation=\"softmax\", name=\"dense_clf_4\"),\n",
    "                                 ])\n",
    "    adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    clf.compile(optimizer=adam, loss='binary_crossentropy')\n",
    "    clf.build(input_shape=(128,40,40,1))\n",
    "    return clf\n",
    "\n",
    "clf = define_model()    \n",
    "clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1291)\n",
    "\n",
    "clf = define_model()\n",
    "\n",
    "\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.00001,\n",
    "    patience=15,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    restore_best_weights=True)\n",
    "ckp = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"best_model_clf.ckp\",\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    save_freq='epoch',\n",
    ")\n",
    "\n",
    "clf.fit(X_tr.astype(np.float32), y_tr.astype(np.float32), \n",
    "                batch_size=128,\n",
    "                epochs=1500,\n",
    "                verbose=1,\n",
    "                validation_split=0.2,\n",
    "                # class_weight = class_weights,\n",
    "                callbacks=[es, ckp] \n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(clf.history.history[\"loss\"], \".:\")\n",
    "plt.plot(clf.history.history[\"val_loss\"], \".:\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(clf.history.history[\"loss\"], \".:\")\n",
    "plt.plot(clf.history.history[\"val_loss\"], \".:\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_tr.argmax(1), pred_y_tr)\n",
    "print(cr)\n",
    "\n",
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(y_tr.argmax(1), pred_y_tr), \n",
    "    columns=tuple(zip([\"pred\"]*3,[0,1,2])), \n",
    "    index=tuple(zip([\"true\"]*3,[0,1,2]))\n",
    ")\n",
    "cm.style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_ts.argmax(1), pred_y_ts)\n",
    "print(cr)\n",
    "\n",
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(y_ts.argmax(1), pred_y_ts),\n",
    "    columns=tuple(zip([\"pred\"]*3,range(3))), \n",
    "    index=tuple(zip([\"true\"]*3,range(3)))\n",
    ")\n",
    "cm.style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start_idx = test_idx[0]\n",
    "test_start_idx"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
